{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, log10\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "benford = {1: .301, \n",
    "           2: .176, \n",
    "           3: .125, \n",
    "           4: .097, \n",
    "           5: .079, \n",
    "           6: .067, \n",
    "           7: .058, \n",
    "           8: .051, \n",
    "           9: .046}\n",
    "\n",
    "def get_first_digit(i: int):\n",
    "    if i == 0:\n",
    "        return 0\n",
    "    return floor(i / (10 ** floor(log10(i))))\n",
    "\n",
    "def data_to_df(data: list[int]) -> pd.DataFrame:\n",
    "    # Take list of data points and return dataframe of first digit frequencies as percentages\n",
    "    range_to_fill = range(1, 10)\n",
    "    fd = [get_first_digit(d) for d in data]\n",
    "    total = len(data)\n",
    "    counts = Counter({key: (Counter(fd)[key]/total - benford[key]) for key in range_to_fill})\n",
    "    df = pd.DataFrame([counts], columns=counts.keys())\n",
    "    return df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lengths of constant strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_string_length(analysis):\n",
    "    strings = analysis.get_strings()  # dex[0].get_strings()\n",
    "    strings = [s.get_value() for s in strings]\n",
    "    strings = list(map(str.strip, strings))\n",
    "\n",
    "    data = list(map(len, strings))\n",
    "\n",
    "    return data_to_df(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sum of Decimal encoded characters of constant strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_chars(s):\n",
    "    return sum(ord(c) for c in s)\n",
    "\n",
    "def fd_string_value(analysis):\n",
    "    strings = analysis.get_strings()  # dex[0].get_strings()\n",
    "    strings = [s.get_value() for s in strings]\n",
    "\n",
    "    strings = list(map(str.strip, strings))\n",
    "\n",
    "    data = list(map(sum_of_chars, strings))\n",
    "\n",
    "    return data_to_df(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lengths of methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_method_lengths(analysis):\n",
    "    methods = analysis.get_methods()\n",
    "\n",
    "    # The above get_methods() method returns a deprecated type, so we get_method() again below to return a usable type.\n",
    "    # External methods don't have available lengths, so we skip past them\n",
    "    method_lengths = [method.get_method().get_length() for method in methods if not method.is_external()]\n",
    "\n",
    "    return data_to_df(method_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of fields in a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_class_fields(analysis):\n",
    "    classes = analysis.get_internal_classes()\n",
    "\n",
    "    fields = [c.get_fields() for c in classes]\n",
    "\n",
    "    fields_count = map(len, fields)\n",
    "\n",
    "    return data_to_df(fields_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of methods in a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_class_methods(analysis):\n",
    "    classes = analysis.get_internal_classes()\n",
    "    methods = [c.get_methods() for c in classes]\n",
    "    methods_count = map(len, methods)\n",
    "    return data_to_df(methods_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bytes -> Hex -> Decimal of classes.dex file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_classes_dex(apk):\n",
    "    all_classes = apk.get_all_dex()\n",
    "\n",
    "    byte = [int(c, 16) for classes in all_classes for c in classes.hex(sep=' ').split(' ')]\n",
    "\n",
    "    return data_to_df(byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "import os\n",
    "from androguard.misc import AnalyzeAPK\n",
    "\n",
    "def evaluate_directory(dir_name):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    progress = progressbar.ProgressBar(max_value=len(os.listdir(dir_name)))\n",
    "\n",
    "    for i, file in list(enumerate(os.listdir(dir_name)))[:10]:\n",
    "        file_path = os.path.join(dir_name, file)\n",
    "        apk,dex,analysis = AnalyzeAPK(file_path)\n",
    "\n",
    "        try:\n",
    "            data = fd_string_length(analysis)\n",
    "            df = pd.concat([df, data])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Excluding APK:\", file)\n",
    "        \n",
    "        progress.update(i+1)\n",
    "\n",
    "    progress.finish()\n",
    "\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Benign APKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 100) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      "  2% (2 of 100) |                        | Elapsed Time: 0:00:20 ETA:   0:16:39\n",
      "  3% (3 of 100) |                        | Elapsed Time: 0:01:32 ETA:   1:56:39\n",
      "  4% (4 of 100) |                        | Elapsed Time: 0:01:49 ETA:   0:27:44\n",
      "  5% (5 of 100) |#                       | Elapsed Time: 0:02:31 ETA:   1:05:27\n",
      "  6% (6 of 100) |#                       | Elapsed Time: 0:02:46 ETA:   0:23:18\n",
      "Requested API level 29 is larger than maximum we have, returning API level 28 instead.\n",
      "  7% (7 of 100) |#                       | Elapsed Time: 0:03:33 ETA:   1:14:03\n",
      "  8% (8 of 100) |#                       | Elapsed Time: 0:03:54 ETA:   0:32:06\n",
      "  9% (9 of 100) |##                      | Elapsed Time: 0:03:56 ETA:   0:17:02\n",
      "Requested API level 31 is larger than maximum we have, returning API level 28 instead.\n",
      " 10% (10 of 100) |##                     | Elapsed Time: 0:04:25 ETA:   0:44:17\n",
      "100% (100 of 100) |######################| Elapsed Time: 0:04:25 Time:  0:04:25\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation(), allow_no_value=True)\n",
    "config.read('config.ini')\n",
    "\n",
    "BENIGN_DIR = config['PATHS']['benign_dir']\n",
    "\n",
    "benign_df = evaluate_directory(BENIGN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Malign APKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (0 of 100) |                        | Elapsed Time: 0:00:00 ETA:  --:--:--\n",
      "  2% (2 of 100) |                        | Elapsed Time: 0:00:01 ETA:   0:01:03\n",
      "Requested API Level could not be found, using 19 instead\n",
      "  3% (3 of 100) |                        | Elapsed Time: 0:00:07 ETA:   0:09:45\n",
      "  4% (4 of 100) |                        | Elapsed Time: 0:00:07 ETA:   0:05:04\n",
      "  5% (5 of 100) |#                       | Elapsed Time: 0:00:11 ETA:   0:06:00\n",
      "  6% (6 of 100) |#                       | Elapsed Time: 0:00:23 ETA:   0:18:20\n",
      "  7% (7 of 100) |#                       | Elapsed Time: 0:00:27 ETA:   0:07:27\n",
      "  8% (8 of 100) |#                       | Elapsed Time: 0:00:32 ETA:   0:07:38\n",
      "  9% (9 of 100) |##                      | Elapsed Time: 0:02:11 ETA:   2:29:31\n",
      " 10% (10 of 100) |##                     | Elapsed Time: 0:03:51 ETA:   2:29:37\n",
      "100% (100 of 100) |######################| Elapsed Time: 0:03:51 Time:  0:03:51\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser(interpolation=configparser.ExtendedInterpolation(), allow_no_value=True)\n",
    "config.read('config.ini')\n",
    "\n",
    "MALIGN_DIR = config['PATHS']['malign_dir']\n",
    "malign_df = evaluate_directory(MALIGN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine benign and malign DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "benign_df['malign'] = 0\n",
    "malign_df['malign'] = 1\n",
    "\n",
    "df = pd.concat([benign_df, malign_df]).reset_index(drop=True)\n",
    "df.to_csv(os.path.join(config['PATHS']['apk_dir'], 'data.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onr-android-malware",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
